{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Thesis Project: collecting tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This is a 'jupyter notebook': a certain kind of program you can use to develop your own software applications. In this notebook we will use the Python computer language and the Twitter API ('application programmer interface') to automatically collect and analyse tweets. \n",
    "\n",
    "This notebook contains cells, i.e., snippets of either code or normal text. We use the text cells (like the current one) to explain what is going on. You can edit a cell by clicking on it. After you made the changes, you can either click 'run' above, or press shift+enter, to execute what is written. In the case of a text cell, this will just display the text in the correct format (try it with this cell!); in case of a code cell, the code will be executed. \n",
    "\n",
    "The next cell will be a code cell where we ask the computer to print a simple sentence for us. Try to change this sentence and then execute the code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note: to use this program, you have to execute all the code in all the cells in the correct order. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about using jupyter notebooks, look for a tutorial online (e.g., https://www.dataquest.io/blog/jupyter-notebook-tutorial/). Most of the questions you have or the problems you encounter will also be solved through a simple google search with the correct keywords.\n",
    "\n",
    "**However, if you have other questions or any problems that you really don't know how to solve, please contact us on Slack and we'll be happy to help or to schedule a meeting. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successful\n"
     ]
    }
   ],
   "source": [
    "from twython import Twython\n",
    "#if this results in an error, you need to install twython first. See guideline document.\n",
    "print('import successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to connect to Twitter using the correct passwords/keys. There is a limit on how many tweets you can collect each 15 minutes (this makes sure the Twitter servers are not overloaded, amongst other reasons).  Running the code below 'logs you in' to the Twitter application. If all goes well, the output should show information on the number of calls ('questions we can ask') we can still perform these 15 minutes. With each call, you can collect 100 Tweets. \n",
    "e.g.: {'/search/tweets': {'limit': 450, 'remaining': 443, 'reset': 1568288620}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 450, 'remaining': 450, 'reset': 1576587984}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APP_KEY = 'yN3VbAb8QZdzD5GPkVuOHLfMN'         #API key\n",
    "APP_SECRET = 'YRdyk39bx9iRPQBhK2Nh1fT32JdGYTrEhqxcEbcpLMIxbT7wKh'   #API secret key\n",
    "twitter = Twython(APP_KEY, APP_SECRET, oauth_version=2)\n",
    "ACCESS_TOKEN = twitter.obtain_access_token()\n",
    "\n",
    "twitter = Twython(APP_KEY, access_token=ACCESS_TOKEN)\n",
    "twitter.get_application_rate_limit_status()['resources']['search']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the code, we will start 'streaming' tweets: collecting newly created tweets based on certain criteria. These tweets will then be saved in a csv file, a file format that you can open with excel, pages, etc. \n",
    "\n",
    "Every time you want to start streaming, run the code in the cells below. It migth take a while before a first tweet is discovered, so there's nothing wrong if no tweet shows up for a while. If a lot of tweets are streamed (like, e.g., when you would use a keyword like 'Trump' or 'Brexit'); make sure to halt the program in time.\n",
    "\n",
    "New tweets will automatically be added to a file with the filename as specified below. You can change the filename (but do keep the extension '.csv'). This file will be created once a first tweet that matches the criteria is discovered, and tweets will be added to the same file regardless of whether you restarted the application in between. The file will be generated in the same folder as the folder where these notebooks are located. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer\n",
    "import csv\n",
    "import os.path\n",
    "\n",
    "filename = 'collected_tweets.csv' #change the filename here \n",
    "delimiter = ';' #change this to ';' or ',' if your software (like excel, numbers...) doesn't show your data in columns \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, we first specify what will happen if we find a tweet that matches our criteria. Currently, it will tell us when a new tweet is collected. If it's not a retweet, its date, place and text will be written to file.\n",
    "\n",
    "There's a lot more information you can access for each tweet. If you want to save more than the date, place and text (e.g., the name of the user) please go to https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object and consult the section 'Tweet Data Dictionary'. List all the properties you want to save to file, and contact us so we can update this part of the code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamer(TwythonStreamer):\n",
    "    def on_success(self, data):\n",
    "        print(\"-------new tweet collected!\")\n",
    "        \n",
    "        if 'retweeted_status' in data:\n",
    "            print(\"but it's a retweet, so we ignore it...\")\n",
    "        else:\n",
    "            \n",
    "            #first we print selected information about the tweet so you can follow what's happing\n",
    "            if data.get('extended_tweet')!= None and data['extended_tweet'].get('full_text')!= None :\n",
    "                print([data['created_at'],data['place'], data['extended_tweet']['full_text']])\n",
    "            else:\n",
    "                print([data['created_at'],data['place'], data['text']])\n",
    "             \n",
    "            \n",
    "            #below we process the information and write it to file\n",
    "            file_exists = os.path.isfile(filename);\n",
    "            with open(filename,'a', encoding='utf-8') as f: #this will add the newly collected tweets to your dataset ('a' = append) \n",
    "                writer = csv.writer(f, delimiter=';')\n",
    "                \n",
    "                ##write a header to the file if it doesn't exist already\n",
    "                if not file_exists: #if it's a new file, we should create a header \n",
    "                    writer.writerow(['Date','Place_Name','Place_Bounding_Box','Text', 'Tweet_Id', 'IsReplyTo_ID','IsReplyTo_Text', 'Hashtags','Urls','Media','User_Screen_Name', 'User_Id', 'User_Followers_Count', 'Checked_Status_At','Retweets_Count','Favourites_Count']) #this is the document header\n",
    "                \n",
    "    \n",
    "                ##format all the results in a new row to append to the file\n",
    "                \n",
    "                #add a value for the date and time of creation of the tweet\n",
    "                row_to_write = [data['created_at']]\n",
    "                \n",
    "                #process location information, if present\n",
    "                if data.get('place')== None:\n",
    "                    row_to_write.append('')\n",
    "                    row_to_write.append('')\n",
    "                else:\n",
    "                    row_to_write.append(data['place']['full_name'])\n",
    "                    row_to_write.append(data['place']['bounding_box'])\n",
    "                \n",
    "                #the text is stored depending on the type of tweet. We use the full text if available ('extended_tweet'), otherwise we use the standard text\n",
    "                if data.get('extended_tweet')!= None and data['extended_tweet'].get('full_text')!= None :\n",
    "                    row_to_write.append(data['extended_tweet']['full_text'])\n",
    "                else:\n",
    "                    row_to_write.append(data['text'])\n",
    "                      \n",
    "                #then we can add a column for the tweet ID\n",
    "                row_to_write.append(data['id'])   \n",
    "                \n",
    "                #if the tweet is a reply, store the original tweet ID\n",
    "                row_to_write.append(data['in_reply_to_status_id'])  \n",
    "            \n",
    "                if(data['in_reply_to_status_id']):  #if the tweet is a reply, the original text can be fetched later\n",
    "                    row_to_write.append('original text to be fetched')\n",
    "                else: #if the tweet is a not reply, this column can be left empty\n",
    "                    row_to_write.append('')\n",
    "                                \n",
    "                #then we can process the hashtags:\n",
    "                hashtags_as_strings = ''\n",
    "                for x in data['entities']['hashtags']:\n",
    "                    hashtags_as_strings = hashtags_as_strings + ', ' + x['text']\n",
    "                row_to_write.append(hashtags_as_strings)    \n",
    "                                \n",
    "                #then we can process the urls:\n",
    "                urls_as_strings = ''\n",
    "                for x in data['entities']['urls']:\n",
    "                    urls_as_strings = urls_as_strings + ', ' + x['url']\n",
    "                row_to_write.append(urls_as_strings)\n",
    "                                \n",
    "                #presence of media \n",
    "                if data['entities'].get(\"media\") != None:\n",
    "                      row_to_write.append('yes')\n",
    "                else:\n",
    "                    row_to_write.append('no')\n",
    "                \n",
    "                \n",
    "                #user information      \n",
    "                row_to_write.append(data['user']['screen_name'])\n",
    "                row_to_write.append(data['user']['id']) \n",
    "                row_to_write.append(data['user']['followers_count'])\n",
    "                                \n",
    "                \n",
    "                #empty values that will later be replaced with retweet count etc. \n",
    "                row_to_write.append('')\n",
    "                row_to_write.append('')\n",
    "                row_to_write.append('')\n",
    "         \n",
    "            \n",
    "                #finally, write everything to file             \n",
    "                writer.writerow(row_to_write)\n",
    "                                \n",
    "    def on_error(self, status_code, data):\n",
    "        print(data)\n",
    "        print(status_code)\n",
    "        # self.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we connect to the twitter stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "OAUTH_TOKEN = '1100028871259377670-qtcMTW2ereJ3A0KIvFguWu0ZmW0n8k'\n",
    "OAUTH_TOKEN_SECRET = 'wnPYmWOds9xD1i1CM9K8gfzMNZ26QoBmXW4JSSA81faRF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you execute the next cell, the streaming will start. This is also the place where you can edit the criteria you want to 'filter' the stream on. There's different types of filters you can use (at the same time):\n",
    "\n",
    "\n",
    "\n",
    "**follow** \t(optional): \tA comma separated list of user IDs, indicating the users to return statuses for in the stream. \n",
    "\n",
    "**track** (optional): \tKeywords to track. Phrases of keywords are specified by a comma-separated list. \n",
    "\n",
    "**locations** \t(optional): \tSpecifies a set of bounding boxes to track. \n",
    "\n",
    "see https://developer.twitter.com/en/docs/tweets/filter-realtime/api-reference/post-statuses-filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:29 +0000 2019', None, \"@AndyWoodturner @jblairreid I've heard talk of an inside job. They were daft, they could have just creamed off a million quids worth, and she'd barely have noticed.\\n\\nI've tried, but failed, to find any sympathy.\"]\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:29 +0000 2019', None, '@idolfess Baekhyun is the time of you getting that job actually sucks haha is the time of time to you haha is the time of time to you haha is the time of time to you haha is the time of time to you haha is the time of time to you haha is \\n\\nBodo amat anjir autotext gua begini wkwkwkwk']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:29 +0000 2019', None, '#NowHiring: #Software Engineer I\\n#Developer #Franklin #Programmer #Developer #jobs\\n‚òë Apply Now ‚òû https://t.co/yaRTY0WLmY https://t.co/Lujn0fqwL7']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:30 +0000 2019', None, 'New #job: Account Support Manager - Automotive Finance Location: Cheshire Salary: ¬£25kpa - ¬£35kpa .. https://t.co/uuZFZDO6aB #jobs #hiring']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:30 +0000 2019', None, '@sudeshna2104 @abhbasak @JasBJP @tjt4002 @sarvadaman1 @SaptarshiMBJP @debashishash123 @DebjaniBhatta20 @Krishanu_Singh This Bangladeshi guy caught by Niamatpur police, Kulti, Paschim Bardhaman. He is telling that so many illegal Bangladeshis are in different part of westbengal involved in different types of job, like rickshaw puller, hawker, maid, servant, sabji wala etc, no docs available.']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:30 +0000 2019', None, 'AI Program Strategy and Growth Lead - Morgan Stanley - [ üìã More Info  https://t.co/EU9hBjX4Pe ] #AI #AiJobs #ArtificialIntelligence  # #jobs #Hiring #Careers #Glasgow #United Kingdom #Cryptocurrency #Blockchain #BTC https://t.co/nMlZ0efSxf']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:31 +0000 2019', None, '@bajankris Why would anyone even ask him about the Arsenal job. Never in a million years.']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:32 +0000 2019', None, 'A Lyft to work in the rain from where I lived near temple three years ago was 7 dollars.  Today, in the same neighborhood, but closer to my job, it is 25 dollars.  Haven‚Äôt I been through enough?']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:32 +0000 2019', None, '[Job] Oil/gas Technician | Company: Perras Home Comfort | Location: Brantford ON Ontario Canada | #Brantford #Oil #and #Gas #Jobs | More info at  https://t.co/n92QoGixOE']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:32 +0000 2019', None, 'Transportation Assistant https://t.co/hYAMDfnrUI']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:33 +0000 2019', None, \"@ZackHallam @northernassist @arrivanorthwest @DiamondBusNW @gnwbus You think that's bad I got told im losing my job because I'm always late thanks the the go north west buses. Sometimes they just dont even show up at all\"]\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:33 +0000 2019', None, 'New #job: Customer Care Coordinator  Location: Slough Salary: 19kpa - 19kpa .. https://t.co/ldyNPJjnoM #jobs #hiring']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:33 +0000 2019', None, 'They did a great job of singing my fave song from CATSüòç\\nSeriously who is the black Cat Man\\U0001f929\\U0001f929\\U0001f929\\U0001f929 he sound so gooood !!!!üò´üò´üò´üò´üò´üò´']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:34 +0000 2019', None, 'The people who impacted you in the past have prepared you for now\\n@Coaching_DNA \\n\\n1st listen of the podcast, nice job!']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:34 +0000 2019', None, \"@Lisamboo @SkyNews When they don't like the number, they simply stop counting. Maggie did with poverty and Cameron did with A&amp;E waiting times. \\n\\nThis government will lie on an industrial scale. And  #BBC will not hold them to account. \\n\\n31 = 50\\n4 = 40\\nZero hours contract = a job\\nDay = night\"]\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:34 +0000 2019', None, '@OfficialMonstaX and of course good job my loves! you did so well, we are very proud of you all ‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:35 +0000 2019', None, 'It was $80.3K/month']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:35 +0000 2019', {'id': '095534ad3107e0e6', 'url': 'https://api.twitter.com/1.1/geo/id/095534ad3107e0e6.json', 'place_type': 'city', 'name': 'Louisville', 'full_name': 'Louisville, KY', 'country_code': 'US', 'country': 'United States', 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-85.847503, 38.108678], [-85.847503, 38.282432], [-85.597188, 38.282432], [-85.597188, 38.108678]]]}, 'attributes': {}}, \"If you're looking for work in #Louisville, KY, check out this job: https://t.co/0l5FF0vW9d #Healthcare\"]\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:35 +0000 2019', None, 'ü§£üòÇü§£üòÇ']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:35 +0000 2019', None, '[Job] Controls Engineer - Electrified Powertrain | Company: B&amp;W Automotive Engineering Mexico | Location: Puebla PUE  Mexico | #Puebla #Automotive #Engineering #Jobs | More info at  https://t.co/igmFJ611zi']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:35 +0000 2019', None, 'got sacked from my job at thorntons after i pissed in chocolate mixer so am now looking for a sugar daddy as my next source of income, am willing to do:\\n‚Ä¢water sports\\n‚Ä¢cock and ball torture\\n‚Ä¢feet tickling\\nexpecially prefer mature gentleman, must have an average annual income']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:35 +0000 2019', None, 'I‚Äôm definitely hiring a maid to clean my apartment for my annual end of the year deep clean.']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:36 +0000 2019', None, \"Don't leave your job to go and fulfill the promise. Daniel was still employed by nebuchadnezzar while he was going after promise\"]\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:36 +0000 2019', None, 'Arteta knows he has options. He can easily stay with successful Pep and City or pressure #Arsenal with the Everton job..  Fool me once..']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:37 +0000 2019', None, '@LivePDNation So sweet to watch this. You can tell he is as loved as much as he gives love. Love it! Great job officer. Thank you for all the good you do. https://t.co/ogUv8nQUvb']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:37 +0000 2019', None, 'Care International Zimbabwe is looking for a Community Visioning Lead. The ideal candidate must have a\\xa0Bachelor‚Äôs degree in the social sciences.\\nhttps://t.co/YnMaaqrjSx\\n\\n#jobszimbabwe #jobseekers https://t.co/MEwPipmZUP']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:38 +0000 2019', None, 'Girl I be hating that shit I be so drained \\U0001f974']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:38 +0000 2019', None, 'When he is voted out of Office he better hope some Republicans feels bad for him and gives him a job']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:38 +0000 2019', None, '[Job] Test Engineering Mgmt 3 | Company: Sanmina Corporation | Location: El Salto JAL  Mexico | #El #Salto #Automotive #Engineering #Jobs | More info at  https://t.co/FlZsiZRaOy']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:38 +0000 2019', None, 'New #job: PA/Office Manager Location: London Salary: 25kpa - 30kpa .. https://t.co/g3FU9jq1HT #jobs']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:38 +0000 2019', None, '@daphnenews @PKonst2d @TassosMorfis @ekathimerini Everything is OK, and thank you all for your comments. XYZContagion cares most for the story to be spread. AthensLive, Tasos Morfis and Petros K. did a great job working with us and we were happy to work with them. What matters is only more people to learn about GVG in Srebrenica']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:39 +0000 2019', None, '@republic Good job!!!']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:39 +0000 2019', None, '@shirIeyt pride had swelled up in Boris‚Äôs chest. Yet, it was never discussed. \\n\\n    It was as if watching a fire when Shirley got a little worked up. Especially over something that he knew. It happened when Boris wouldn‚Äôt let him go on the dangerous job. \\n\\n   Still, if Shirley could see ‚Äî']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:39 +0000 2019', None, 'Men , peace &amp; knowledge']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:40 +0000 2019', None, 'Congrats Mason! \\nGreat job Mom &amp; Dr P!']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:40 +0000 2019', {'id': 'fa3435044b52ecc7', 'url': 'https://api.twitter.com/1.1/geo/id/fa3435044b52ecc7.json', 'place_type': 'city', 'name': 'Newark', 'full_name': 'Newark, NJ', 'country_code': 'US', 'country': 'United States', 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-74.25136, 40.679997], [-74.25136, 40.788991], [-74.118336, 40.788991], [-74.118336, 40.679997]]]}, 'attributes': {}}, \"@jNewOrleans It's fun but I'm like damn you still don't have a job \\U0001f974\"]\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:40 +0000 2019', None, 'New #job: Data Engineer Location: Eindhoven Salary: ¬£50kpa - ¬£80kpa .. https://t.co/CprC8RdAtq #OscarJobs']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:41 +0000 2019', None, 'New #job: Hadoop Administrator Location: Amsterdam Salary: 60kpa - 80kpa .. https://t.co/Nmq8dccoWU #OscarJobs']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:41 +0000 2019', None, '@AncestralVoices If you need any spiritual help on any of these: bewitched people problem\\n*looking for a husband or wife\\n*performing sex on dream. \\n*looking for a child.\\n*spiritual husband.\\n*spiritual wife.\\n*miscarriage.\\n*job opportunities.\\n*high positions at work.\\nWin court cases.\\nBlood diseases']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:41 +0000 2019', None, \"@LindseyGrahamSC @realDonaldTrump @SenSchumer You wouldn't acknowledge truth to save your job, literally.\"]\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:42 +0000 2019', None, \"@CapitalOfficial I'd love that job xx\"]\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:43 +0000 2019', None, 'Hoje √© dia de fazer o job q eu gosto \\U0001f970\\U0001f970\\U0001f970']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:43 +0000 2019', {'id': '00c55f041e27dc51', 'url': 'https://api.twitter.com/1.1/geo/id/00c55f041e27dc51.json', 'place_type': 'city', 'name': 'Staten Island', 'full_name': 'Staten Island, NY', 'country_code': 'US', 'country': 'United States', 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-74.255641, 40.495865], [-74.255641, 40.648887], [-74.052253, 40.648887], [-74.052253, 40.495865]]]}, 'attributes': {}}, \"@PatrickHanlon14 @neeratanden Unions have fought for medical coverage for members. I have pvt insurance thru my job &amp; I wish to keep it. Medicare for all.....who want it. Many of us want to keep our insurance. Anyone who doesn't have, can do medicare option.\"]\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:44 +0000 2019', None, 'You going to up that UBI to cover for the sick leave they don‚Äôt have at their hourly job?']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:44 +0000 2019', None, \"Is this a a custom paint job? Can't seem to find it anywhere on the Internet https://t.co/RW5qkL4fcL\"]\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:44 +0000 2019', None, \"@MAMETCHl I kept having job that I had to finish in exchange for 13h per day. I learn the lesson and work less time now to not feeling worse but I don't have that overflowing inspiration. Not to say that I don't draw for myself anymore... But it's ok I'm working in it\"]\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:45 +0000 2019', None, '@flasportsbuzz Really? The hiring of Don Shula blows all of them out of the water.  Drafting Dan Marino that late in the 1st round worked out pretty well too.  UM successfully recruiting Jim Kelly out of PA and beating Penn State is what started everything for the Canes. That was pretty big...']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:45 +0000 2019', None, 'We are #hiring Customer Service Representative - Train to Management!! in Hilliard, OH https://t.co/aRLMX9D9XF #jobs #Hilliard']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:46 +0000 2019', {'id': '319ee7b36c9149da', 'url': 'https://api.twitter.com/1.1/geo/id/319ee7b36c9149da.json', 'place_type': 'city', 'name': 'Arlington', 'full_name': 'Arlington, VA', 'country_code': 'US', 'country': 'United States', 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-77.172219, 38.827378], [-77.172219, 38.934311], [-77.031779, 38.934311], [-77.031779, 38.827378]]]}, 'attributes': {}}, '@ThisSideOp @senatorshoshana If prosecutors had some personal skin in the game‚Äîsuch as automatic permanent disbarment for any false guilty plea‚Äîthen you‚Äôd see false plea rates drop to near zero, I predict. There‚Äôs a difference between ‚Äúpretty sure‚Äù that D‚Äôs really guilty and ‚Äúsure enough to bet my job.‚Äù']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:46 +0000 2019', None, '@SchexniderJ That‚Äôs Cool Mr. Karl. Those Poor Little Kids Doesn‚Äôt understand what‚Äôs going on when you arrive. That‚Äôs one of the hardest part of the Job.']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:46 +0000 2019', None, 'Ëã±Ë™û„ÅßÁî∑ÂèãÈÅî„Çí‰Ωú„Çã„Åü„ÇÅ„ÅÆÁî∑„ÅÆ„Åü„ÇÅ„ÅÆÂçòË™û‰æãÊñáÈõÜ\\nblow job‚Üí„Éï‚óØ„É©\\n‰æãÊñá) Hey dude, I got a blow job from this girl! (Tinder„ÅÆ„Éó„É≠„Éï„Ç£„Éº„É´ÂÜôÁúü„ÇíË¶ã„Åõ„Å™„Åå„Çâ)\\nË®≥) ‰ªäÊó•„Åì„ÅÆÂ≠ê„Å´„Éï‚óØ„É©„Åó„Å¶„ÇÇ„Çâ„Å£„Åü„Çì„Å†„Åú\\n#Ëã±‰ºöË©±']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:46 +0000 2019', None, '#Hiring: #LVN/ LPN, Licensed Vocational Nurse/ Licensed Practical Nurse-Nursing Relief\\n#BSN #LPN #RN #Texarkana  #Nurse \\nApply Here‚û£  https://t.co/Y0yjyi9D2q']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:47 +0000 2019', None, '@MoyoZuva Kwete. Just coz his boss offered me his job. Lolol']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:47 +0000 2019', None, \"@spectatorindex I don't know about the other countries but India and Mexico above the USA? If Mexico would be a better place to live and work than the US they'd have no reason to seek a job in the US, and the thing would be the other way, americans looking for jobs in Mexico.\"]\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:48 +0000 2019', None, '@peeboymk1982']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:48 +0000 2019', None, 'If hand jobs are given with your hands then a blow job must be wild']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:48 +0000 2019', None, '@RudyGiuliani Funny only you and @realDonaldTrump say so.  Of course she did get in the way of your ‚ÄúDrug Deal‚Äù as Bolton put it, didn‚Äôt she?  Even Sondland, who was hired for a job not even a job, was installed to carry out your scheme and admitted it under oath.  Maybe you should just shutup']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:48 +0000 2019', None, '@Keir_Starmer That‚Äôs your definition. Another way of looking at it is he is getting the job done and won‚Äôt be delayed anymore. Doing what he said he would do. You should try it sometime. Bye']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:48 +0000 2019', None, 'my job scheduled me overnight xmas eve and xmas ! i aint wann have to show them how much idgaf but fckit']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:48 +0000 2019', None, 'New #job: Lead Technical Sales Engineer  Location: Galway .. https://t.co/Olek8ZZVq1 #jobs #hiring']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:50 +0000 2019', None, '@MonbebeZelle @RandomVillain1 @OfficialMonstaX @STARSHIPent @zelle_lie @SoulsSeriesGirl @Mombebe_Jess @SunnyBu14796364 @Christy2695 @kpop_britney @Jewels74228285 @pisey_min @RedfireStella @freikje Yep, that‚Äôs my plan too. I‚Äôm too exhausted to deal with anything right now hahaha first on my agenda is finding a new job...  #Ïñ∏Ï†úÎÇò_Î™¨Ïóë_Í≥ÅÏóê_ÏûàÏùÑÍ≤å\\n#WeWontStopForWonho \\n@OfficialMonstaX @STARSHIPent']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:50 +0000 2019', None, '@TrumpLadyFran @ReneeCarrollAZ @AnnaApp91838450 We never thought for a minute that God would send someone who couldn‚Äôt handle the job! Thank you First Lady and Mr President!']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:50 +0000 2019', None, 'Esta es la l√≥gica de los zurdos privilegiados.']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:50 +0000 2019', None, '@LAOFCS Grammatical error perhaps? I‚Äôm sure you meant to award her actress of A decade meaning she‚Äôs earned her 10 year on the job badge']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:50 +0000 2019', None, \"@AMiraculousFit @AngelSandalphon It's ok Raphael, I.. just... Well you are ok now. \\n[I'm not sure if Uriel would have ended the job...]\\n\\nUh Raphael could you check me something? I need a second healer oppinion.\"]\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:50 +0000 2019', None, 'fear that your possible clinginess and efforts to keep their only job']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:51 +0000 2019', None, 'RT appr√©ci√©s.\\nRecherche √©tudiant\\n- en Anglais qui veut un petit job \\n-v√©hicul√©\\n-avec de l‚Äôexp√©rience avec les enfants !!']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:51 +0000 2019', None, '@humain974 @EmmanuelMacron C‚Äôest pas mon job mais mnt lisez le communiqu√© du d√©put√© Lorion et vs verrez que l‚ÄôEtat ne veut finalement pas investir dans cette transition ü§∑\\u200d‚ôÄÔ∏è lobby d‚Äôune transnationale ? Probablement...']\n",
      "-------new tweet collected!\n",
      "['Tue Dec 17 12:51:51 +0000 2019', None, '@rickyg14 @JaniceOwen @thedonnsays In this economy I‚Äôd be happy I still had a job that pays a hell of a lot has great benefits and pension. You think in downturns there are just massive raises thrown around still?? And they aren‚Äôt ‚Äúlosing‚Äù anything it‚Äôs going into a pension which means it will be growing']\n",
      "-------new tweet collected!\n",
      "but it's a retweet, so we ignore it...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7549873fcc21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m stream = MyStreamer(APP_KEY, APP_SECRET,\n\u001b[1;32m      2\u001b[0m                     OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatuses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'job,hiring'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'extended'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/twython/streaming/types.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://stream.twitter.com/%s/statuses/filter.json'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m               \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/twython/streaming/api.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, url, method, params)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36miter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mpending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_unicode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_unicode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpending\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stream = MyStreamer(APP_KEY, APP_SECRET,\n",
    "                    OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "stream.statuses.filter(track='job,hiring', tweet_mode='extended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check status: look up the favorites and retweets counts after given time period (and, if a reply, add the text of the original tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to determine, for tweets we collected in the past, the number of times they have been retweeted and the number of times they have been favorited. To have a fair comparison between tweets this should always be done in more or less the same 'time window'. I.e., here we choose to use always 10 to 14 days later. This means that once you collected tweets you should run this code at least once between 10 and 14 days later. There are 3 possible results: \n",
    "- the tweet is created between 10 to 14 days ago: great! We look up its counts. \n",
    "- the tweet is created less than 10 days ago: the time window in which you should run this code again is added in the file.\n",
    "- the tweet is created less than 14 days ago and hasn't been checked: you missed the window and the tweet has expired. These tweets should be excluded from your analysis (please contact us so we can help). \n",
    "\n",
    "In addition to this, this code will add the original tweet's text to the dataset if the tweet was a reply (independent of the number of days).\n",
    "\n",
    "Note that the updated dataset will be stored in a new file. You can choose the filename below. **Do not give it the same name as your original file!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we will first determine the correct time window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will look up the tweets created between: \n",
      "2019-11-14 12:14:00.425579\n",
      "and \n",
      "2019-11-18 12:14:00.425579\n"
     ]
    }
   ],
   "source": [
    "#the file of collected tweets that you want to get the counts for:\n",
    "filename = 'collected_tweets.csv' #change the filename here \n",
    "\n",
    "#the file with the updated datatset\n",
    "temp_copy_file = 'collected_tweets_updated_thuNov28.csv' #change the filename here (different from original!)\n",
    "\n",
    "\n",
    "#the time period we consider (from 'max_days_back' days ago to 'min_days_back' days ago  )\n",
    "max_days_back = 14 #days ## do not change this\n",
    "min_days_back = 10 #days ## do not change this\n",
    "\n",
    "current_date = datetime.now()\n",
    "max_date_back = current_date - timedelta(days=max_days_back)\n",
    "min_date_back = current_date - timedelta(days=min_days_back)\n",
    "\n",
    "print('we will look up the tweets created between: ')\n",
    "print(max_date_back)\n",
    "print('and ')\n",
    "print(min_date_back)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_Date = 0\n",
    "col_ID = 4\n",
    "col_isReply_ID = 5\n",
    "col_isReply_Text = 6 \n",
    "col_Checked_Status_At = 13\n",
    "col_Retweets_Count= 14\n",
    "col_Favourites_Count = 15\n",
    "\n",
    "with open(filename, mode='r', encoding='utf-8') as csv_file:\n",
    "\n",
    "    csv_reader = csv.reader(csv_file, delimiter=delimiter)\n",
    "    line_count = 0\n",
    "    \n",
    "    with open (temp_copy_file,'w', encoding='utf-8') as temp_csv_copy:\n",
    "        \n",
    "        wtr = csv.writer(temp_csv_copy)\n",
    "\n",
    "        for tweet in csv_reader:\n",
    "            if line_count > 0: #skip the header\n",
    "\n",
    "                #get the time the tweet was created\n",
    "                time_of_creation = datetime.strptime(tweet[col_Date],  \"%a %b %d %H:%M:%S %z %Y\") #'%a %b %d %H:%M:%S %Y')\n",
    "                time_of_creation = time_of_creation.replace(tzinfo=None)\n",
    "                \n",
    "                #did we already get the counts?\n",
    "                if not tweet[col_Retweets_Count]: #we didn't check before\n",
    "                    #is this time is within our bounds, fetch the original tweet from twitter and check its counts\n",
    "                    if time_of_creation > max_date_back and time_of_creation < min_date_back:\n",
    "                        ID = tweet[col_ID]\n",
    "                        fetched_tweet = twitter.show_status(id=ID)\n",
    "                        tweet[col_Retweets_Count] = fetched_tweet['retweet_count']\n",
    "                        tweet[col_Favourites_Count] = fetched_tweet['favorite_count']\n",
    "                        tweet[col_Checked_Status_At] =  current_date\n",
    "                    else:\n",
    "                        if time_of_creation < max_date_back: #the tweet wasn't checked within the bounds and has now expired\n",
    "                             tweet[col_Checked_Status_At] = 'expired'; \n",
    "                        else:\n",
    "                            min_date = time_of_creation + timedelta(days=min_days_back)\n",
    "                            min_date = min_date.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "                            max_date = time_of_creation + timedelta(days=max_days_back)\n",
    "                            max_date = max_date.strftime(\"%d/%m/%Y,, %H:%M:%S\") \n",
    "                            tweet[col_Checked_Status_At] = 'to be checked between ' + min_date + ' and ' + max_date\n",
    "                            \n",
    "                #is the tweet a reply, then add the original tweet's text\n",
    "                if tweet[col_isReply_ID]:\n",
    "                    fetched_tweet = twitter.show_status(id=tweet[col_isReply_ID])\n",
    "                    tweet[col_isReply_Text] = fetched_tweet['text']\n",
    "\n",
    "            line_count += 1\n",
    "            wtr.writerow(tweet);\n",
    "    \n",
    "csv_file.close()\n",
    "temp_csv_copy.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
